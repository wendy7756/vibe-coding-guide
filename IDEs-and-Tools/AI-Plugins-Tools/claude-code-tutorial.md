# Claude Code ä½¿ç”¨æ•™ç¨‹ (2025å¹´æœ€æ–°ç‰ˆ)

<div align="center">ä¸­æ–‡ | [English](claude-code-tutorial-en.md)</div>

## ç›®å½•
- [ç®€ä»‹](#ç®€ä»‹)
- [2025å¹´æœ€æ–°åŠŸèƒ½](#2025å¹´æœ€æ–°åŠŸèƒ½)
- [å®šä»·æ–¹æ¡ˆ](#å®šä»·æ–¹æ¡ˆ)
- [å®‰è£…å’Œè®¾ç½®](#å®‰è£…å’Œè®¾ç½®)
- [æ ¸å¿ƒåŠŸèƒ½è¯¦è§£](#æ ¸å¿ƒåŠŸèƒ½è¯¦è§£)
- [ä½¿ç”¨åœºæ™¯å’Œæ¡ˆä¾‹](#ä½¿ç”¨åœºæ™¯å’Œæ¡ˆä¾‹)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

## ç®€ä»‹

Claude Codeæ˜¯ç”±Anthropicå¼€å‘çš„AIç¼–ç¨‹åŠ©æ‰‹ï¼ŒåŸºäºClaudeç³»åˆ—å¤§å‹è¯­è¨€æ¨¡å‹ã€‚2025å¹´ç‰ˆæœ¬å¸¦æ¥äº†é©å‘½æ€§çš„Computer Use APIã€æ··åˆæ¨ç†èƒ½åŠ›å’Œæ‰©å±•æ€ç»´åŠŸèƒ½ï¼Œæˆä¸ºAIç¼–ç¨‹é¢†åŸŸçš„æ–°æ ‡æ†ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **æ··åˆæ¨ç†æ¨¡å‹**: æ”¯æŒå¿«é€Ÿæ¨ç†å’Œæ·±åº¦æ€è€ƒä¸¤ç§æ¨¡å¼
- **Computer Use API**: å¯ä»¥ç›´æ¥æ“ä½œè®¡ç®—æœºç•Œé¢
- **å¤šæ¨¡æ€æ”¯æŒ**: å¤„ç†æ–‡æœ¬ã€å›¾åƒã€ä»£ç å’Œæ–‡æ¡£
- **æ‰©å±•æ€ç»´**: æ”¯æŒå¤æ‚é—®é¢˜çš„æ­¥éª¤åŒ–è§£å†³
- **APIé›†æˆ**: çµæ´»çš„APIæ¥å£ï¼Œæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€

## 2025å¹´æœ€æ–°åŠŸèƒ½

### ğŸš€ Claude 3.7 Sonnet å‘å¸ƒ
- **å‘å¸ƒæ—¶é—´**: 2025å¹´2æœˆ24æ—¥
- **æ··åˆæ¨ç†**: åŒæ¨¡å¼æ“ä½œï¼Œæ ‡å‡†å’Œæ‰©å±•æ€ç»´æ¨¡å¼
- **200K Tokenè¾“å‡º**: å¤§å¹…æå‡è¾“å‡ºå®¹é‡
- **ç¼–ç¨‹æ€§èƒ½**: åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸Šè¾¾åˆ°SOTAæ°´å¹³
- **åŠ¨ä½œæ‰©å±•**: æ”¯æŒè¿­ä»£å‡½æ•°è°ƒç”¨å’Œç¯å¢ƒäº¤äº’

### ğŸ¤– Claude 4 Sonnet å’Œ Opus 4
- **Claude 4 Sonnet**: å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦çš„æœ€æ–°ç‰ˆæœ¬
- **Claude Opus 4**: æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œä¸“ä¸ºå¤æ‚é—®é¢˜æ±‚è§£è®¾è®¡
- **è§†è§‰èƒ½åŠ›**: æ”¹è¿›çš„å›¾åƒç†è§£å’Œåˆ†æèƒ½åŠ›
- **å·¥å…·ä½¿ç”¨**: å¢å¼ºçš„å‡½æ•°è°ƒç”¨å’ŒAPIé›†æˆ

### ğŸ–¥ï¸ Computer Use API
- **å±å¹•æ§åˆ¶**: ç›´æ¥æ“ä½œGUIç•Œé¢
- **è‡ªåŠ¨åŒ–ä»»åŠ¡**: æ‰§è¡Œå¤æ‚çš„è®¡ç®—æœºæ“ä½œ
- **è·¨å¹³å°æ”¯æŒ**: æ”¯æŒWindowsã€macOSå’ŒLinux
- **å®‰å…¨é™åˆ¶**: ä¸¥æ ¼çš„æƒé™æ§åˆ¶å’Œå®‰å…¨æªæ–½

### ğŸ§  æ‰©å±•æ€ç»´èƒ½åŠ›
- **æ·±åº¦æ¨ç†**: æ”¯æŒå¤æ‚é—®é¢˜çš„å¤šæ­¥éª¤åˆ†æ
- **æ€ç»´é“¾**: æ¸…æ™°å±•ç¤ºæ¨ç†è¿‡ç¨‹
- **è‡ªæˆ‘ä¿®æ­£**: èƒ½å¤Ÿæ£€æŸ¥å’Œä¿®æ­£è‡ªå·±çš„æ¨ç†
- **åˆ›æ–°æ€ç»´**: æ”¯æŒåˆ›é€ æ€§é—®é¢˜è§£å†³

## å®šä»·æ–¹æ¡ˆ

### APIå®šä»·ï¼ˆæŒ‰Tokenè®¡è´¹ï¼‰

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ (æ¯1M tokens) | è¾“å‡ºä»·æ ¼ (æ¯1M tokens) | é€‚ç”¨åœºæ™¯ |
|------|----------------------|----------------------|----------|
| **Claude 3 Haiku** | $0.25 | $1.25 | ç®€å•ä»»åŠ¡å’Œå¿«é€Ÿå“åº” |
| **Claude 3 Sonnet** | $3.00 | $15.00 | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ |
| **Claude 3.5 Sonnet** | $3.00 | $15.00 | å¢å¼ºç‰ˆå¹³è¡¡æ¨¡å‹ |
| **Claude 3.7 Sonnet** | $3.00 | $15.00 | æœ€æ–°æ··åˆæ¨ç†æ¨¡å‹ |
| **Claude 4 Sonnet** | $3.00 | $15.00 | æœ€æ–°å¹³è¡¡æ¨¡å‹ |
| **Claude 3 Opus** | $15.00 | $75.00 | å¤æ‚ä»»åŠ¡å’Œé«˜è´¨é‡éœ€æ±‚ |
| **Claude Opus 4** | $15.00 | $75.00 | æœ€å¼ºå¤§çš„æ¨¡å‹ |

### è®¢é˜…è®¡åˆ’

| è®¡åˆ’ | ä»·æ ¼ | ç‰¹æ€§ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **å…è´¹å±‚** | $0 | æœ‰é™è¯·æ±‚ï¼ŒåŸºç¡€åŠŸèƒ½ | è¯•ç”¨å’Œå­¦ä¹  |
| **Proè®¡åˆ’** | $20/æœˆ | æ›´å¤šè¯·æ±‚ï¼Œä¼˜å…ˆé˜Ÿåˆ— | ä¸ªäººå¼€å‘è€… |
| **Teamè®¡åˆ’** | $25/ç”¨æˆ·/æœˆ | å›¢é˜Ÿåä½œï¼Œæ›´é«˜é™åˆ¶ | å°å›¢é˜Ÿ |
| **Enterprise** | å®šåˆ¶ | æ— é™åˆ¶ï¼Œä¸“å±æ”¯æŒ | ä¼ä¸šå®¢æˆ· |

## å®‰è£…å’Œè®¾ç½®

### 1. è·å–APIå¯†é’¥
```bash
# è®¿é—®Anthropicå®˜ç½‘
https://console.anthropic.com/

# æ­¥éª¤
1. æ³¨å†ŒAnthropicè´¦æˆ·
2. éªŒè¯é‚®ç®±å’Œæ‰‹æœºå·
3. è¿›å…¥APIæ§åˆ¶å°
4. åˆ›å»ºæ–°çš„APIå¯†é’¥
5. ä¿å­˜å¯†é’¥åˆ°å®‰å…¨ä½ç½®
```

### 2. ç¯å¢ƒè®¾ç½®
```bash
# å®‰è£…Python SDK
pip install anthropic

# è®¾ç½®ç¯å¢ƒå˜é‡
export ANTHROPIC_API_KEY="your_api_key_here"

# æˆ–è€…åˆ›å»º .env æ–‡ä»¶
echo "ANTHROPIC_API_KEY=your_api_key_here" > .env
```

### 3. åŸºæœ¬é…ç½®
```python
# Python é…ç½®ç¤ºä¾‹
import anthropic
import os

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = anthropic.Anthropic(
    api_key=os.getenv("ANTHROPIC_API_KEY")
)

# åŸºæœ¬é…ç½®
default_config = {
    "model": "claude-3.7-sonnet",
    "max_tokens": 4096,
    "temperature": 0.3,
    "system": "You are a helpful AI programming assistant."
}
```

### 4. å¤šè¯­è¨€SDK
```bash
# JavaScript/TypeScript
npm install @anthropic-ai/sdk

# Python
pip install anthropic

# Java
<dependency>
    <groupId>com.anthropic</groupId>
    <artifactId>anthropic-java</artifactId>
    <version>1.0.0</version>
</dependency>

# Go
go get github.com/anthropic/anthropic-go
```

## æ ¸å¿ƒåŠŸèƒ½è¯¦è§£

### 1. ä»£ç ç”Ÿæˆå’Œè¡¥å…¨
```python
# ç¤ºä¾‹ï¼šç”Ÿæˆå®Œæ•´çš„APIæœåŠ¡
import anthropic

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=2000,
    system="You are an expert Python developer. Generate clean, production-ready code.",
    messages=[
        {
            "role": "user",
            "content": "Create a FastAPI service for user management with CRUD operations, including authentication and input validation."
        }
    ]
)

print(response.content[0].text)
```

### 2. æ··åˆæ¨ç†æ¨¡å¼
```python
# å¯ç”¨æ‰©å±•æ€ç»´æ¨¡å¼
response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=4000,
    system="Use extended thinking mode for complex problems.",
    messages=[
        {
            "role": "user",
            "content": "Design a distributed system architecture for a high-traffic e-commerce platform. Consider scalability, reliability, and performance."
        }
    ]
)
```

### 3. Computer Use API
```python
# è®¡ç®—æœºä½¿ç”¨ç¤ºä¾‹
def use_computer_api(task_description):
    response = client.messages.create(
        model="claude-3.7-sonnet",
        max_tokens=1000,
        tools=[
            {
                "type": "computer_20241022",
                "name": "computer",
                "display_width_px": 1920,
                "display_height_px": 1080
            }
        ],
        messages=[
            {
                "role": "user",
                "content": f"Please help me with this task: {task_description}"
            }
        ]
    )
    return response

# ä½¿ç”¨ç¤ºä¾‹
result = use_computer_api("Open a text editor and create a simple HTML page")
```

### 4. å¤šæ¨¡æ€å¤„ç†
```python
# å›¾åƒå’Œä»£ç åˆ†æ
import base64

def analyze_code_screenshot(image_path):
    with open(image_path, "rb") as image_file:
        image_data = base64.b64encode(image_file.read()).decode()
    
    response = client.messages.create(
        model="claude-3.7-sonnet",
        max_tokens=1000,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": image_data
                        }
                    },
                    {
                        "type": "text",
                        "text": "Analyze this code screenshot and suggest improvements."
                    }
                ]
            }
        ]
    )
    
    return response.content[0].text

# ä½¿ç”¨ç¤ºä¾‹
analysis = analyze_code_screenshot("code_screenshot.png")
```

### 5. å‡½æ•°è°ƒç”¨å’Œå·¥å…·ä½¿ç”¨
```python
# å®šä¹‰å·¥å…·å‡½æ•°
def get_weather(location):
    # æ¨¡æ‹Ÿå¤©æ°”APIè°ƒç”¨
    return f"Weather in {location}: 22Â°C, sunny"

# é…ç½®å·¥å…·
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather for a location",
        "input_schema": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "City name"
                }
            },
            "required": ["location"]
        }
    }
]

# ä½¿ç”¨å·¥å…·
response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=1000,
    tools=tools,
    messages=[
        {
            "role": "user",
            "content": "What's the weather like in San Francisco?"
        }
    ]
)
```

## ä½¿ç”¨åœºæ™¯å’Œæ¡ˆä¾‹

### åœºæ™¯1: å¤æ‚ç®—æ³•å®ç°
```python
# éœ€æ±‚ï¼šå®ç°ä¸€ä¸ªé«˜æ•ˆçš„å›¾ç®—æ³•
prompt = """
å®ç°ä¸€ä¸ªç”¨äºç¤¾äº¤ç½‘ç»œåˆ†æçš„å›¾ç®—æ³•ï¼ŒåŒ…å«ï¼š
1. å›¾çš„è¡¨ç¤ºå’Œå­˜å‚¨
2. æœ€çŸ­è·¯å¾„ç®—æ³•
3. ç¤¾åŒºæ£€æµ‹ç®—æ³•
4. å½±å“åŠ›åˆ†æ
5. å¹¶è¡Œå¤„ç†æ”¯æŒ
6. å®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹
"""

response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=4000,
    system="You are an expert in graph algorithms and parallel computing.",
    messages=[{"role": "user", "content": prompt}]
)

# Claudeç”Ÿæˆçš„å®Œæ•´å›¾ç®—æ³•å®ç°
import networkx as nx
from collections import defaultdict, deque
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import heapq

class SocialNetworkAnalyzer:
    def __init__(self):
        self.graph = nx.Graph()
        self.adjacency_list = defaultdict(list)
        self.node_attributes = {}
    
    def add_node(self, node_id, attributes=None):
        """æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­"""
        self.graph.add_node(node_id)
        self.node_attributes[node_id] = attributes or {}
    
    def add_edge(self, node1, node2, weight=1):
        """æ·»åŠ è¾¹åˆ°å›¾ä¸­"""
        self.graph.add_edge(node1, node2, weight=weight)
        self.adjacency_list[node1].append((node2, weight))
        self.adjacency_list[node2].append((node1, weight))
    
    def dijkstra_shortest_path(self, start, end):
        """ä½¿ç”¨Dijkstraç®—æ³•è®¡ç®—æœ€çŸ­è·¯å¾„"""
        distances = {node: float('inf') for node in self.graph.nodes()}
        distances[start] = 0
        priority_queue = [(0, start)]
        previous = {}
        
        while priority_queue:
            current_distance, current_node = heapq.heappop(priority_queue)
            
            if current_node == end:
                break
                
            if current_distance > distances[current_node]:
                continue
                
            for neighbor, weight in self.adjacency_list[current_node]:
                distance = current_distance + weight
                
                if distance < distances[neighbor]:
                    distances[neighbor] = distance
                    previous[neighbor] = current_node
                    heapq.heappush(priority_queue, (distance, neighbor))
        
        # é‡æ„è·¯å¾„
        path = []
        current = end
        while current in previous:
            path.append(current)
            current = previous[current]
        path.append(start)
        path.reverse()
        
        return path, distances[end]
    
    def detect_communities(self, resolution=1.0):
        """ä½¿ç”¨Louvainç®—æ³•æ£€æµ‹ç¤¾åŒº"""
        import community as community_louvain
        
        partition = community_louvain.best_partition(self.graph, resolution=resolution)
        communities = defaultdict(list)
        
        for node, community_id in partition.items():
            communities[community_id].append(node)
        
        return dict(communities)
    
    def calculate_influence(self, node_id):
        """è®¡ç®—èŠ‚ç‚¹å½±å“åŠ›ï¼ˆç»“åˆåº¦ä¸­å¿ƒæ€§ã€ä»‹æ•°ä¸­å¿ƒæ€§å’ŒPageRankï¼‰"""
        degree_centrality = nx.degree_centrality(self.graph)[node_id]
        betweenness_centrality = nx.betweenness_centrality(self.graph)[node_id]
        pagerank = nx.pagerank(self.graph)[node_id]
        
        # ç»¼åˆå½±å“åŠ›å¾—åˆ†
        influence_score = (
            0.4 * degree_centrality +
            0.3 * betweenness_centrality +
            0.3 * pagerank
        )
        
        return influence_score
    
    def parallel_influence_analysis(self, top_k=10):
        """å¹¶è¡Œè®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„å½±å“åŠ›"""
        nodes = list(self.graph.nodes())
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            influence_scores = list(executor.map(self.calculate_influence, nodes))
        
        # æ’åºå¹¶è¿”å›top_k
        node_influence = list(zip(nodes, influence_scores))
        node_influence.sort(key=lambda x: x[1], reverse=True)
        
        return node_influence[:top_k]

# æµ‹è¯•ç”¨ä¾‹
def test_social_network_analyzer():
    analyzer = SocialNetworkAnalyzer()
    
    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    for i in range(10):
        analyzer.add_node(i, {"name": f"User{i}"})
    
    edges = [(0, 1), (0, 2), (1, 3), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9)]
    for edge in edges:
        analyzer.add_edge(edge[0], edge[1])
    
    # æµ‹è¯•æœ€çŸ­è·¯å¾„
    path, distance = analyzer.dijkstra_shortest_path(0, 9)
    print(f"æœ€çŸ­è·¯å¾„ä»0åˆ°9: {path}, è·ç¦»: {distance}")
    
    # æµ‹è¯•ç¤¾åŒºæ£€æµ‹
    communities = analyzer.detect_communities()
    print(f"æ£€æµ‹åˆ°çš„ç¤¾åŒº: {communities}")
    
    # æµ‹è¯•å½±å“åŠ›åˆ†æ
    top_influencers = analyzer.parallel_influence_analysis(5)
    print(f"Top 5 å½±å“åŠ›ç”¨æˆ·: {top_influencers}")

if __name__ == "__main__":
    test_social_network_analyzer()
```

### åœºæ™¯2: è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬
```python
# éœ€æ±‚ï¼šåˆ›å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–éƒ¨ç½²å’Œç›‘æ§ç³»ç»Ÿ
prompt = """
åˆ›å»ºä¸€ä¸ªPythonè„šæœ¬ï¼Œå®ç°ï¼š
1. è‡ªåŠ¨åŒ–åº”ç”¨éƒ¨ç½²
2. ç³»ç»Ÿç›‘æ§å’Œå‘Šè­¦
3. æ—¥å¿—åˆ†æ
4. è‡ªåŠ¨æ•…éšœæ¢å¤
5. æ€§èƒ½æŒ‡æ ‡æ”¶é›†
6. é‚®ä»¶é€šçŸ¥ç³»ç»Ÿ
"""

response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=3000,
    system="You are a DevOps expert specializing in automation and monitoring.",
    messages=[{"role": "user", "content": prompt}]
)

# Claudeç”Ÿæˆçš„è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬
import subprocess
import psutil
import smtplib
import time
import logging
import json
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import requests
import os

class AutomationSystem:
    def __init__(self, config_file="automation_config.json"):
        self.config = self.load_config(config_file)
        self.setup_logging()
        self.alert_cooldown = {}
    
    def load_config(self, config_file):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "email": {
                "smtp_server": "smtp.gmail.com",
                "smtp_port": 587,
                "username": "your_email@gmail.com",
                "password": "your_password",
                "recipients": ["admin@company.com"]
            },
            "monitoring": {
                "cpu_threshold": 80,
                "memory_threshold": 85,
                "disk_threshold": 90,
                "check_interval": 60
            },
            "services": [
                {"name": "nginx", "port": 80},
                {"name": "application", "port": 8000}
            ]
        }
        
        if os.path.exists(config_file):
            with open(config_file, 'r') as f:
                return json.load(f)
        return default_config
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('automation.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def send_email_alert(self, subject, message):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        try:
            msg = MIMEMultipart()
            msg['From'] = self.config['email']['username']
            msg['To'] = ', '.join(self.config['email']['recipients'])
            msg['Subject'] = subject
            
            msg.attach(MIMEText(message, 'plain'))
            
            server = smtplib.SMTP(self.config['email']['smtp_server'], self.config['email']['smtp_port'])
            server.starttls()
            server.login(self.config['email']['username'], self.config['email']['password'])
            server.send_message(msg)
            server.quit()
            
            self.logger.info(f"é‚®ä»¶å‘Šè­¦å·²å‘é€: {subject}")
        except Exception as e:
            self.logger.error(f"å‘é€é‚®ä»¶å¤±è´¥: {e}")
    
    def check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        cpu_usage = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        alerts = []
        
        if cpu_usage > self.config['monitoring']['cpu_threshold']:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_usage}%")
        
        if memory.percent > self.config['monitoring']['memory_threshold']:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent}%")
        
        if disk.percent > self.config['monitoring']['disk_threshold']:
            alerts.append(f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk.percent}%")
        
        if alerts:
            alert_message = "\n".join(alerts)
            self.send_alert_with_cooldown("ç³»ç»Ÿèµ„æºå‘Šè­¦", alert_message)
            
            # å°è¯•è‡ªåŠ¨æ¢å¤
            self.auto_recovery()
        
        return {
            "cpu": cpu_usage,
            "memory": memory.percent,
            "disk": disk.percent,
            "timestamp": datetime.now().isoformat()
        }
    
    def check_service_health(self):
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        service_status = {}
        
        for service in self.config['services']:
            try:
                response = requests.get(f"http://localhost:{service['port']}", timeout=10)
                service_status[service['name']] = response.status_code == 200
            except Exception as e:
                service_status[service['name']] = False
                self.logger.warning(f"æœåŠ¡ {service['name']} æ£€æŸ¥å¤±è´¥: {e}")
                
                # å°è¯•é‡å¯æœåŠ¡
                self.restart_service(service['name'])
        
        return service_status
    
    def restart_service(self, service_name):
        """é‡å¯æœåŠ¡"""
        try:
            subprocess.run(['systemctl', 'restart', service_name], check=True)
            self.logger.info(f"æœåŠ¡ {service_name} å·²é‡å¯")
            
            # ç­‰å¾…æœåŠ¡å¯åŠ¨
            time.sleep(5)
            
            # éªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸
            if self.verify_service_restart(service_name):
                self.send_email_alert(
                    f"æœåŠ¡æ¢å¤æˆåŠŸ",
                    f"æœåŠ¡ {service_name} å·²æˆåŠŸé‡å¯å¹¶æ¢å¤æ­£å¸¸"
                )
            else:
                self.send_email_alert(
                    f"æœåŠ¡æ¢å¤å¤±è´¥",
                    f"æœåŠ¡ {service_name} é‡å¯åä»ç„¶æ— æ³•æ­£å¸¸å·¥ä½œ"
                )
        except subprocess.CalledProcessError as e:
            self.logger.error(f"é‡å¯æœåŠ¡ {service_name} å¤±è´¥: {e}")
            self.send_email_alert(
                f"æœåŠ¡é‡å¯å¤±è´¥",
                f"æ— æ³•é‡å¯æœåŠ¡ {service_name}: {e}"
            )
    
    def verify_service_restart(self, service_name):
        """éªŒè¯æœåŠ¡é‡å¯æ˜¯å¦æˆåŠŸ"""
        # æŸ¥æ‰¾å¯¹åº”çš„ç«¯å£é…ç½®
        for service in self.config['services']:
            if service['name'] == service_name:
                try:
                    response = requests.get(f"http://localhost:{service['port']}", timeout=10)
                    return response.status_code == 200
                except:
                    return False
        return False
    
    def auto_recovery(self):
        """è‡ªåŠ¨æ¢å¤æ“ä½œ"""
        self.logger.info("æ‰§è¡Œè‡ªåŠ¨æ¢å¤æ“ä½œ...")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        subprocess.run(['find', '/tmp', '-type', 'f', '-atime', '+7', '-delete'], 
                      capture_output=True)
        
        # é‡å¯é«˜å†…å­˜ä½¿ç”¨çš„è¿›ç¨‹ï¼ˆç¤ºä¾‹ï¼‰
        try:
            result = subprocess.run(['ps', 'aux', '--sort', '-rss'], 
                                  capture_output=True, text=True)
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è¿›ç¨‹ç®¡ç†é€»è¾‘
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨æ¢å¤å¤±è´¥: {e}")
    
    def send_alert_with_cooldown(self, subject, message, cooldown_minutes=30):
        """å¸¦å†·å´æ—¶é—´çš„å‘Šè­¦å‘é€"""
        now = datetime.now()
        alert_key = f"{subject}_{message}"
        
        if alert_key in self.alert_cooldown:
            time_diff = (now - self.alert_cooldown[alert_key]).total_seconds() / 60
            if time_diff < cooldown_minutes:
                return
        
        self.alert_cooldown[alert_key] = now
        self.send_email_alert(subject, message)
    
    def collect_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "system": self.check_system_resources(),
            "services": self.check_service_health(),
            "processes": len(psutil.pids()),
            "network": {
                "connections": len(psutil.net_connections()),
                "io_counters": psutil.net_io_counters()._asdict()
            }
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(f"metrics_{datetime.now().strftime('%Y%m%d')}.json", 'a') as f:
            f.write(json.dumps(metrics) + '\n')
        
        return metrics
    
    def deploy_application(self, app_path, service_name):
        """éƒ¨ç½²åº”ç”¨"""
        try:
            self.logger.info(f"å¼€å§‹éƒ¨ç½²åº”ç”¨: {service_name}")
            
            # åœæ­¢æœåŠ¡
            subprocess.run(['systemctl', 'stop', service_name], check=True)
            
            # å¤‡ä»½å½“å‰ç‰ˆæœ¬
            backup_path = f"/backup/{service_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            subprocess.run(['cp', '-r', app_path, backup_path], check=True)
            
            # éƒ¨ç½²æ–°ç‰ˆæœ¬ï¼ˆè¿™é‡Œå‡è®¾æ–°ç‰ˆæœ¬åœ¨/tmp/new_versionç›®å½•ï¼‰
            subprocess.run(['cp', '-r', '/tmp/new_version/*', app_path], check=True)
            
            # å¯åŠ¨æœåŠ¡
            subprocess.run(['systemctl', 'start', service_name], check=True)
            
            # éªŒè¯éƒ¨ç½²
            time.sleep(10)
            if self.verify_service_restart(service_name):
                self.send_email_alert(
                    "éƒ¨ç½²æˆåŠŸ",
                    f"åº”ç”¨ {service_name} å·²æˆåŠŸéƒ¨ç½²å¹¶è¿è¡Œæ­£å¸¸"
                )
                self.logger.info(f"åº”ç”¨ {service_name} éƒ¨ç½²æˆåŠŸ")
            else:
                # å›æ»š
                self.rollback_deployment(backup_path, app_path, service_name)
                
        except Exception as e:
            self.logger.error(f"éƒ¨ç½²å¤±è´¥: {e}")
            self.send_email_alert("éƒ¨ç½²å¤±è´¥", f"åº”ç”¨ {service_name} éƒ¨ç½²å¤±è´¥: {e}")
    
    def rollback_deployment(self, backup_path, app_path, service_name):
        """å›æ»šéƒ¨ç½²"""
        try:
            self.logger.info(f"å¼€å§‹å›æ»šåº”ç”¨: {service_name}")
            
            subprocess.run(['systemctl', 'stop', service_name], check=True)
            subprocess.run(['rm', '-rf', app_path], check=True)
            subprocess.run(['cp', '-r', backup_path, app_path], check=True)
            subprocess.run(['systemctl', 'start', service_name], check=True)
            
            self.send_email_alert(
                "åº”ç”¨å›æ»šå®Œæˆ",
                f"åº”ç”¨ {service_name} å·²å›æ»šåˆ°ä¹‹å‰ç‰ˆæœ¬"
            )
            
        except Exception as e:
            self.logger.error(f"å›æ»šå¤±è´¥: {e}")
            self.send_email_alert("å›æ»šå¤±è´¥", f"åº”ç”¨ {service_name} å›æ»šå¤±è´¥: {e}")
    
    def run_monitoring_loop(self):
        """è¿è¡Œç›‘æ§å¾ªç¯"""
        self.logger.info("å¼€å§‹ç›‘æ§ç³»ç»Ÿ...")
        
        while True:
            try:
                metrics = self.collect_metrics()
                self.logger.info(f"æŒ‡æ ‡æ”¶é›†å®Œæˆ: CPU={metrics['system']['cpu']}%, "
                               f"å†…å­˜={metrics['system']['memory']}%")
                
                time.sleep(self.config['monitoring']['check_interval'])
                
            except KeyboardInterrupt:
                self.logger.info("ç›‘æ§ç³»ç»Ÿå·²åœæ­¢")
                break
            except Exception as e:
                self.logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(10)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    automation = AutomationSystem()
    
    # å¯ä»¥å•ç‹¬è¿è¡Œå„ä¸ªåŠŸèƒ½
    # automation.deploy_application("/var/www/myapp", "myapp")
    # automation.collect_metrics()
    
    # æˆ–è€…è¿è¡ŒæŒç»­ç›‘æ§
    automation.run_monitoring_loop()
```

### åœºæ™¯3: æ•°æ®åˆ†æå’Œå¯è§†åŒ–
```python
# éœ€æ±‚ï¼šåˆ›å»ºä¸€ä¸ªå…¨é¢çš„æ•°æ®åˆ†æå·¥å…·
prompt = """
åˆ›å»ºä¸€ä¸ªPythonæ•°æ®åˆ†æå·¥å…·ï¼ŒåŒ…å«ï¼š
1. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
2. ç»Ÿè®¡åˆ†æå’Œå‡è®¾æ£€éªŒ
3. æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ
4. äº¤äº’å¼æ•°æ®å¯è§†åŒ–
5. æŠ¥å‘Šç”Ÿæˆ
6. å®æ—¶æ•°æ®å¤„ç†
"""

response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=4000,
    system="You are a data science expert with extensive experience in Python analytics.",
    messages=[{"role": "user", "content": prompt}]
)

# Claudeç”Ÿæˆçš„æ•°æ®åˆ†æå·¥å…·
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import streamlit as st
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error
import joblib
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class DataAnalyzer:
    def __init__(self):
        self.data = None
        self.processed_data = None
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        
    def load_data(self, file_path, file_type='csv'):
        """åŠ è½½æ•°æ®"""
        try:
            if file_type == 'csv':
                self.data = pd.read_csv(file_path)
            elif file_type == 'excel':
                self.data = pd.read_excel(file_path)
            elif file_type == 'json':
                self.data = pd.read_json(file_path)
            
            print(f"æ•°æ®åŠ è½½æˆåŠŸ: {self.data.shape}")
            return self.data
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def data_profiling(self):
        """æ•°æ®æ¦‚è§ˆå’Œåˆ†æ"""
        if self.data is None:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        profile = {
            'shape': self.data.shape,
            'columns': list(self.data.columns),
            'dtypes': self.data.dtypes.to_dict(),
            'missing_values': self.data.isnull().sum().to_dict(),
            'duplicate_rows': self.data.duplicated().sum(),
            'memory_usage': self.data.memory_usage(deep=True).sum() / 1024**2,  # MB
            'numeric_summary': self.data.describe(),
            'categorical_summary': self.data.select_dtypes(include=['object']).describe()
        }
        
        return profile
    
    def clean_data(self, drop_duplicates=True, handle_missing='drop', outlier_method='iqr'):
        """æ•°æ®æ¸…æ´—"""
        if self.data is None:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        self.processed_data = self.data.copy()
        
        # åˆ é™¤é‡å¤è¡Œ
        if drop_duplicates:
            self.processed_data.drop_duplicates(inplace=True)
        
        # å¤„ç†ç¼ºå¤±å€¼
        if handle_missing == 'drop':
            self.processed_data.dropna(inplace=True)
        elif handle_missing == 'fill_mean':
            numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
            self.processed_data[numeric_cols] = self.processed_data[numeric_cols].fillna(
                self.processed_data[numeric_cols].mean()
            )
        elif handle_missing == 'fill_median':
            numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
            self.processed_data[numeric_cols] = self.processed_data[numeric_cols].fillna(
                self.processed_data[numeric_cols].median()
            )
        
        # å¤„ç†å¼‚å¸¸å€¼
        if outlier_method == 'iqr':
            numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                Q1 = self.processed_data[col].quantile(0.25)
                Q3 = self.processed_data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                self.processed_data = self.processed_data[
                    (self.processed_data[col] >= lower_bound) & 
                    (self.processed_data[col] <= upper_bound)
                ]
        
        print(f"æ•°æ®æ¸…æ´—å®Œæˆ: {self.processed_data.shape}")
        return self.processed_data
    
    def statistical_analysis(self, column1, column2=None, test_type='correlation'):
        """ç»Ÿè®¡åˆ†æ"""
        if self.processed_data is None:
            return "è¯·å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—"
        
        results = {}
        
        if test_type == 'correlation' and column2:
            # ç›¸å…³æ€§åˆ†æ
            correlation = self.processed_data[column1].corr(self.processed_data[column2])
            results['correlation'] = correlation
            results['p_value'] = stats.pearsonr(
                self.processed_data[column1], 
                self.processed_data[column2]
            )[1]
        
        elif test_type == 'normality':
            # æ­£æ€æ€§æ£€éªŒ
            statistic, p_value = stats.shapiro(self.processed_data[column1])
            results['shapiro_statistic'] = statistic
            results['shapiro_p_value'] = p_value
            results['is_normal'] = p_value > 0.05
        
        elif test_type == 't_test' and column2:
            # tæ£€éªŒ
            group1 = self.processed_data[self.processed_data[column2] == 
                                       self.processed_data[column2].unique()[0]][column1]
            group2 = self.processed_data[self.processed_data[column2] == 
                                       self.processed_data[column2].unique()[1]][column1]
            statistic, p_value = stats.ttest_ind(group1, group2)
            results['t_statistic'] = statistic
            results['p_value'] = p_value
            results['significant'] = p_value < 0.05
        
        return results
    
    def create_visualizations(self, chart_type='distribution', columns=None):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if self.processed_data is None:
            return "è¯·å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—"
        
        fig = make_subplots(rows=2, cols=2, 
                           subplot_titles=('åˆ†å¸ƒå›¾', 'ç›¸å…³æ€§çƒ­åŠ›å›¾', 'ç®±çº¿å›¾', 'æ•£ç‚¹å›¾'))
        
        if chart_type == 'distribution' and columns:
            # åˆ†å¸ƒå›¾
            fig.add_trace(
                go.Histogram(x=self.processed_data[columns[0]], name=columns[0]),
                row=1, col=1
            )
        
        if len(columns) >= 2:
            # æ•£ç‚¹å›¾
            fig.add_trace(
                go.Scatter(x=self.processed_data[columns[0]], 
                          y=self.processed_data[columns[1]], 
                          mode='markers',
                          name=f'{columns[0]} vs {columns[1]}'),
                row=2, col=2
            )
        
        # ç›¸å…³æ€§çƒ­åŠ›å›¾
        numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 1:
            corr_matrix = self.processed_data[numeric_cols].corr()
            fig.add_trace(
                go.Heatmap(z=corr_matrix.values,
                          x=corr_matrix.columns,
                          y=corr_matrix.columns,
                          colorscale='RdBu',
                          name='ç›¸å…³æ€§'),
                row=1, col=2
            )
        
        fig.update_layout(height=800, title_text="æ•°æ®åˆ†æå¯è§†åŒ–")
        return fig
    
    def train_model(self, target_column, model_type='classification', test_size=0.2):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
        if self.processed_data is None:
            return "è¯·å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—"
        
        # å‡†å¤‡æ•°æ®
        X = self.processed_data.drop(columns=[target_column])
        y = self.processed_data[target_column]
        
        # å¤„ç†åˆ†ç±»å˜é‡
        categorical_cols = X.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            if col not in self.encoders:
                self.encoders[col] = LabelEncoder()
                X[col] = self.encoders[col].fit_transform(X[col])
            else:
                X[col] = self.encoders[col].transform(X[col])
        
        # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            if 'scaler' not in self.scalers:
                self.scalers['scaler'] = StandardScaler()
                X[numeric_cols] = self.scalers['scaler'].fit_transform(X[numeric_cols])
            else:
                X[numeric_cols] = self.scalers['scaler'].transform(X[numeric_cols])
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # è®­ç»ƒæ¨¡å‹
        if model_type == 'classification':
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            model.fit(X_train, y_train)
            
            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True)
            
            results = {
                'model': model,
                'accuracy': accuracy,
                'classification_report': report,
                'feature_importance': dict(zip(X.columns, model.feature_importances_))
            }
            
        else:  # regression
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X_train, y_train)
            
            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            
            results = {
                'model': model,
                'mse': mse,
                'rmse': rmse,
                'r2_score': model.score(X_test, y_test),
                'feature_importance': dict(zip(X.columns, model.feature_importances_))
            }
        
        self.models[target_column] = model
        return results
    
    def generate_report(self, output_path='analysis_report.html'):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if self.processed_data is None:
            return "è¯·å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—"
        
        report_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ•°æ®åˆ†ææŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .section {{ margin: 20px 0; }}
                .metric {{ display: inline-block; margin: 10px; padding: 10px; 
                          border: 1px solid #ddd; border-radius: 5px; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <h1>æ•°æ®åˆ†ææŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <div class="section">
                <h2>æ•°æ®æ¦‚è§ˆ</h2>
                <div class="metric">
                    <strong>æ•°æ®å½¢çŠ¶:</strong> {self.processed_data.shape}
                </div>
                <div class="metric">
                    <strong>åˆ—æ•°:</strong> {len(self.processed_data.columns)}
                </div>
                <div class="metric">
                    <strong>è¡Œæ•°:</strong> {len(self.processed_data)}
                </div>
            </div>
            
            <div class="section">
                <h2>æ•°æ®è´¨é‡</h2>
                <div class="metric">
                    <strong>ç¼ºå¤±å€¼:</strong> {self.processed_data.isnull().sum().sum()}
                </div>
                <div class="metric">
                    <strong>é‡å¤è¡Œ:</strong> {self.processed_data.duplicated().sum()}
                </div>
            </div>
            
            <div class="section">
                <h2>æ•°å€¼ç‰¹å¾ç»Ÿè®¡</h2>
                {self.processed_data.describe().to_html()}
            </div>
            
            <div class="section">
                <h2>åˆ†ç±»ç‰¹å¾ç»Ÿè®¡</h2>
                {self.processed_data.select_dtypes(include=['object']).describe().to_html()}
            </div>
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_html)
        
        print(f"åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path
    
    def real_time_processing(self, data_stream):
        """å®æ—¶æ•°æ®å¤„ç†"""
        processed_stream = []
        
        for data_point in data_stream:
            # åº”ç”¨ç›¸åŒçš„æ¸…æ´—å’Œé¢„å¤„ç†æ­¥éª¤
            processed_point = self.apply_preprocessing(data_point)
            
            # å¦‚æœæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¿›è¡Œé¢„æµ‹
            if self.models:
                for target, model in self.models.items():
                    prediction = model.predict([processed_point])[0]
                    processed_point[f'{target}_prediction'] = prediction
            
            processed_stream.append(processed_point)
        
        return processed_stream
    
    def apply_preprocessing(self, data_point):
        """åº”ç”¨é¢„å¤„ç†æ­¥éª¤åˆ°å•ä¸ªæ•°æ®ç‚¹"""
        # è¿™é‡Œåº”è¯¥åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç†æ­¥éª¤
        # åŒ…æ‹¬ç¼–ç ã€æ ‡å‡†åŒ–ç­‰
        return data_point
    
    def save_model(self, target_column, file_path):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if target_column in self.models:
            model_data = {
                'model': self.models[target_column],
                'scaler': self.scalers.get('scaler'),
                'encoders': self.encoders
            }
            joblib.dump(model_data, file_path)
            print(f"æ¨¡å‹å·²ä¿å­˜: {file_path}")
        else:
            print(f"æœªæ‰¾åˆ°æ¨¡å‹: {target_column}")
    
    def load_model(self, file_path, target_column):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            model_data = joblib.load(file_path)
            self.models[target_column] = model_data['model']
            if model_data['scaler']:
                self.scalers['scaler'] = model_data['scaler']
            if model_data['encoders']:
                self.encoders = model_data['encoders']
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {file_path}")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# Streamlit åº”ç”¨ç•Œé¢
def create_streamlit_app():
    st.title("æ•°æ®åˆ†æå·¥å…·")
    
    analyzer = DataAnalyzer()
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶", type=['csv', 'excel', 'json'])
    
    if uploaded_file is not None:
        # åŠ è½½æ•°æ®
        file_type = uploaded_file.name.split('.')[-1]
        analyzer.load_data(uploaded_file, file_type)
        
        # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
        st.subheader("æ•°æ®æ¦‚è§ˆ")
        st.write(analyzer.data_profiling())
        
        # æ•°æ®æ¸…æ´—
        st.subheader("æ•°æ®æ¸…æ´—")
        handle_missing = st.selectbox("ç¼ºå¤±å€¼å¤„ç†", ['drop', 'fill_mean', 'fill_median'])
        outlier_method = st.selectbox("å¼‚å¸¸å€¼å¤„ç†", ['iqr', 'none'])
        
        if st.button("æ‰§è¡Œæ¸…æ´—"):
            analyzer.clean_data(handle_missing=handle_missing, outlier_method=outlier_method)
            st.success("æ•°æ®æ¸…æ´—å®Œæˆ")
        
        # å¯è§†åŒ–
        if analyzer.processed_data is not None:
            st.subheader("æ•°æ®å¯è§†åŒ–")
            columns = st.multiselect("é€‰æ‹©åˆ—", analyzer.processed_data.columns)
            
            if len(columns) > 0:
                fig = analyzer.create_visualizations(columns=columns)
                st.plotly_chart(fig, use_container_width=True)
            
            # æ¨¡å‹è®­ç»ƒ
            st.subheader("æ¨¡å‹è®­ç»ƒ")
            target_column = st.selectbox("ç›®æ ‡åˆ—", analyzer.processed_data.columns)
            model_type = st.selectbox("æ¨¡å‹ç±»å‹", ['classification', 'regression'])
            
            if st.button("è®­ç»ƒæ¨¡å‹"):
                results = analyzer.train_model(target_column, model_type)
                st.write("æ¨¡å‹è®­ç»ƒç»“æœ:", results)
            
            # ç”ŸæˆæŠ¥å‘Š
            if st.button("ç”ŸæˆæŠ¥å‘Š"):
                report_path = analyzer.generate_report()
                st.success(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = DataAnalyzer()
    
    # ç¤ºä¾‹ï¼šåŠ è½½å’Œåˆ†ææ•°æ®
    # analyzer.load_data('sample_data.csv')
    # profile = analyzer.data_profiling()
    # print(profile)
    
    # è¿è¡ŒStreamlitåº”ç”¨
    # streamlit run data_analyzer.py
    create_streamlit_app()
```

### åœºæ™¯4: è‡ªç„¶è¯­è¨€å¤„ç†API
```python
# éœ€æ±‚ï¼šåˆ›å»ºä¸€ä¸ªæ–‡æœ¬åˆ†æAPIæœåŠ¡
prompt = """
åˆ›å»ºä¸€ä¸ªFastAPIæœåŠ¡ï¼Œæä¾›ä»¥ä¸‹NLPåŠŸèƒ½ï¼š
1. æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
2. å®ä½“è¯†åˆ«
3. æ–‡æœ¬æ‘˜è¦
4. å…³é”®è¯æå–
5. æ–‡æœ¬åˆ†ç±»
6. è¯­è¨€æ£€æµ‹
7. æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
"""

response = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=3000,
    system="You are an NLP expert specializing in text analysis and API development.",
    messages=[{"role": "user", "content": prompt}]
)

# Claudeç”Ÿæˆçš„NLP APIæœåŠ¡
# è¿™é‡Œå±•ç¤ºç”Ÿæˆçš„ä»£ç æ¡†æ¶ï¼Œå®Œæ•´å®ç°ä¼šæ›´é•¿
```

## æœ€ä½³å®è·µ

### 1. æˆæœ¬ä¼˜åŒ–ç­–ç•¥
```python
# æ™ºèƒ½é€‰æ‹©æ¨¡å‹
def choose_model_by_task(task_complexity):
    if task_complexity == 'simple':
        return 'claude-3-haiku'
    elif task_complexity == 'medium':
        return 'claude-3.7-sonnet'
    else:
        return 'claude-opus-4'

# ç¼“å­˜ç»“æœ
import hashlib
import json
import os

class ResponseCache:
    def __init__(self, cache_dir='cache'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def get_cache_key(self, prompt, model):
        content = f"{prompt}_{model}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_cached_response(self, prompt, model):
        cache_key = self.get_cache_key(prompt, model)
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        if os.path.exists(cache_file):
            with open(cache_file, 'r') as f:
                return json.load(f)
        return None
    
    def save_response(self, prompt, model, response):
        cache_key = self.get_cache_key(prompt, model)
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        with open(cache_file, 'w') as f:
            json.dump(response, f)
```

### 2. å®‰å…¨å’Œéšç§ä¿æŠ¤
```python
# æ•°æ®è„±æ•
import re

def sanitize_prompt(prompt):
    """ç§»é™¤æ•æ„Ÿä¿¡æ¯"""
    # ç§»é™¤é‚®ç®±
    prompt = re.sub(r'\S+@\S+\.\S+', '[EMAIL]', prompt)
    # ç§»é™¤ç”µè¯å·ç 
    prompt = re.sub(r'\b\d{3}-\d{3}-\d{4}\b', '[PHONE]', prompt)
    # ç§»é™¤èº«ä»½è¯å·ç­‰
    prompt = re.sub(r'\b\d{15}|\d{18}\b', '[ID]', prompt)
    
    return prompt

# è¯·æ±‚é™åˆ¶
from functools import wraps
import time

class RateLimiter:
    def __init__(self, max_requests=100, time_window=3600):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = {}
    
    def is_allowed(self, user_id):
        now = time.time()
        if user_id not in self.requests:
            self.requests[user_id] = []
        
        # æ¸…ç†è¿‡æœŸè¯·æ±‚
        self.requests[user_id] = [
            req_time for req_time in self.requests[user_id]
            if now - req_time < self.time_window
        ]
        
        if len(self.requests[user_id]) >= self.max_requests:
            return False
        
        self.requests[user_id].append(now)
        return True
```

### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
```python
import time
import random
from functools import wraps

def retry_with_backoff(max_retries=3, backoff_factor=1.5):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    
                    wait_time = backoff_factor ** attempt + random.uniform(0, 1)
                    time.sleep(wait_time)
            
        return wrapper
    return decorator

@retry_with_backoff(max_retries=3)
def call_claude_api(prompt, model='claude-3.7-sonnet'):
    response = client.messages.create(
        model=model,
        max_tokens=1000,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text
```

### 4. æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—
```python
import logging
import time
from datetime import datetime

class APIMonitor:
    def __init__(self):
        self.setup_logging()
        self.metrics = {
            'request_count': 0,
            'total_tokens': 0,
            'total_cost': 0.0,
            'avg_response_time': 0.0
        }
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('claude_api.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def log_request(self, prompt, model, response_time, tokens_used):
        self.metrics['request_count'] += 1
        self.metrics['total_tokens'] += tokens_used
        self.metrics['avg_response_time'] = (
            (self.metrics['avg_response_time'] * (self.metrics['request_count'] - 1) + response_time) 
            / self.metrics['request_count']
        )
        
        self.logger.info(f"è¯·æ±‚å®Œæˆ - æ¨¡å‹: {model}, å“åº”æ—¶é—´: {response_time:.2f}s, "
                        f"Tokenä½¿ç”¨: {tokens_used}")
    
    def get_metrics(self):
        return self.metrics
```

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„Claudeæ¨¡å‹ï¼Ÿ
**A**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©ï¼š
- **ç®€å•ä»»åŠ¡**: Claude 3 Haikuï¼ˆå¿«é€Ÿã€ä½æˆæœ¬ï¼‰
- **å¹³è¡¡éœ€æ±‚**: Claude 3.7 Sonnetï¼ˆæ€§èƒ½ä¸æˆæœ¬å¹³è¡¡ï¼‰
- **å¤æ‚ä»»åŠ¡**: Claude Opus 4ï¼ˆæœ€é«˜æ€§èƒ½ï¼‰

### Q2: å¦‚ä½•æ§åˆ¶APIä½¿ç”¨æˆæœ¬ï¼Ÿ
**A**: 
- å®ç°è¯·æ±‚ç¼“å­˜æœºåˆ¶
- æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- è®¾ç½®Tokené™åˆ¶
- ä½¿ç”¨æ‰¹å¤„ç†å‡å°‘è¯·æ±‚æ¬¡æ•°
- ç›‘æ§å’Œåˆ†æä½¿ç”¨æƒ…å†µ

### Q3: Computer Use APIæœ‰å“ªäº›é™åˆ¶ï¼Ÿ
**A**: 
- éœ€è¦æ˜ç¡®çš„æƒé™æˆæƒ
- ä¸èƒ½æ‰§è¡Œå±é™©æ“ä½œ
- æœ‰ä¸¥æ ¼çš„å®‰å…¨æ£€æŸ¥
- ä»…æ”¯æŒç‰¹å®šçš„åº”ç”¨åœºæ™¯

### Q4: å¦‚ä½•å¤„ç†APIé™åˆ¶å’Œé€Ÿç‡é™åˆ¶ï¼Ÿ
**A**: 
- å®ç°é‡è¯•æœºåˆ¶
- ä½¿ç”¨æŒ‡æ•°é€€é¿ç®—æ³•
- ç›‘æ§APIä½¿ç”¨æƒ…å†µ
- é¢„ç•™ç¼“å†²æ—¶é—´
- è€ƒè™‘ä½¿ç”¨å¤šä¸ªAPIå¯†é’¥

### Q5: å¦‚ä½•ç¡®ä¿æ•°æ®å®‰å…¨å’Œéšç§ï¼Ÿ
**A**: 
- æ•°æ®è„±æ•å¤„ç†
- ä½¿ç”¨HTTPSä¼ è¾“
- ä¸åœ¨æç¤ºä¸­åŒ…å«æ•æ„Ÿä¿¡æ¯
- å®šæœŸè½®æ¢APIå¯†é’¥
- éµå¾ªæ•°æ®ä¿æŠ¤æ³•è§„

## å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- [Anthropicå®˜æ–¹æ–‡æ¡£](https://docs.anthropic.com/)
- [Claude APIå‚è€ƒ](https://docs.anthropic.com/claude/reference/)
- [Computer Use APIæŒ‡å—](https://docs.anthropic.com/claude/docs/computer-use)

### å®šä»·å’Œè®¡è´¹
- [APIå®šä»·é¡µé¢](https://www.anthropic.com/pricing)
- [Tokenè®¡ç®—å™¨](https://platform.anthropic.com/token-calculator)
- [æˆæœ¬ä¼˜åŒ–æŒ‡å—](https://apidog.com/blog/claude-api-cost/)

### æŠ€æœ¯èµ„æº
- [Claude 3.7 Sonnetå‘å¸ƒè¯´æ˜](https://aimlapi.com/models/claude-3-7-sonnet-api)
- [Claude Codeä½¿ç”¨æ•™ç¨‹](https://www.youtube.com/watch?v=P_pTypZZL4c)
- [Python SDKæ–‡æ¡£](https://github.com/anthropics/anthropic-sdk-python)

### ç¤¾åŒºå’Œæ”¯æŒ
- [Anthropicç¤¾åŒºè®ºå›](https://community.anthropic.com/)
- [DiscordæœåŠ¡å™¨](https://discord.gg/anthropic)
- [GitHub Issues](https://github.com/anthropics/anthropic-sdk-python/issues)

### æœ€ä½³å®è·µ
- [æç¤ºå·¥ç¨‹æŒ‡å—](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [å®‰å…¨æœ€ä½³å®è·µ](https://docs.anthropic.com/claude/docs/safety-best-practices)
- [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](https://docs.anthropic.com/claude/docs/performance-optimization)

---

**æ›´æ–°æ—¥æœŸ**: 2025å¹´7æœˆ
**ç‰ˆæœ¬**: v2.0
**ä½œè€…**: Vibe Coding Guideå›¢é˜Ÿ

**å…¶ä»–è¯­è¨€ç‰ˆæœ¬**: [English](claude-code-tutorial-en.md) 